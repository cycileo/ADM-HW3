{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Homework 3](https://github.com/Sapienza-University-Rome/ADM/tree/master/2024/Homework_3) - Michelin restaurants in Italy\n",
    "![iStock-654454404-777x518](https://a.storyblok.com/f/125576/2448x1220/327bb24d32/hero_update_michelin.jpg/m/1224x0/filters:format(webp))\n",
    "\n",
    "## 1. Data collection\n",
    "\n",
    "For the data collection, we wrote the required function in a `data_collection.py` module. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collection import save_links, download_html_from_link_file, html_to_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the overview of the main functions for each step, together with the code to run. \n",
    "\n",
    "Every function has an optional `data_folder` argument wich server the purpose to set the working data directory. \n",
    "We tought this to be useful, for example to set the date of the data collection as the directory name. \n",
    "This is useful, as the Michelin list of restaurant is constantly updated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'DATA 24-11-09'\n",
    "# date of last data collection, yy-mm-dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.1. Get the list of Michelin restaurants\n",
    "   #### **Function**: `save_links`\n",
    "   - **Description**: \n",
    "     Collects restaurant links from the Michelin Guide website starting from the provided `start_url`. The links are saved into a text file (`restaurant_links.txt`) within a specified data folder.\n",
    "   - **Input**: \n",
    "     - `start_url`: URL of the Michelin Guide page to start scraping.\n",
    "   - **Optional Input**: \n",
    "     - `file_name`: name of the output file; by default it is `restaurant_links.txt`.\n",
    "     - `data_folder`: the folder where datas will be stored; by default it is `DATA`.\n",
    "   - **Output**:\n",
    "     - A text file containing restaurant links, one per line, saved in the `data_folder`.\n",
    "   - **Key Features**:\n",
    "     - Automatically detects the number of pages to scrape.\n",
    "     - Skips scraping if the links file already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links already collected.\n",
      "There are 1982 link already collected\n"
     ]
    }
   ],
   "source": [
    "start_url = \"https://guide.michelin.com/en/it/restaurants\"\n",
    "save_links(start_url, data_folder = data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.2. Crawl Michelin restaurant pages\n",
    "   #### **Function**: `download_html_from_link_file`\n",
    "   - **Description**: \n",
    "     Downloads the HTML from every URL in the input `file_name`, and saves them to a structured folder (`DATA/HTMLs/page_X`).\n",
    "   - **Input (all optional)**:\n",
    "     - `file_name`: name of the file with the links; by default it is `restaurant_links.txt`.\n",
    "     - `data_folder`: the folder where datas will be stored; by default it is `DATA`.\n",
    "   - **Output**:\n",
    "     - Saves the HTML files in a structured folder `DATA/HTMLs/page_X`. \n",
    "   - **Key Features**:\n",
    "     - Uses `ThreadPoolExecutor` to speed up the process\n",
    "     - Skips existing HTML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download HTMLs: 100%|██████████| 1982/1982 [00:00<00:00, 7230.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All html files have been saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_html_from_link_file(data_folder = data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.3 Parse downloaded pages\n",
    "\n",
    "#### **Function**: `extract_info_from_html`\n",
    "- **Description**:  \n",
    "  Parses a restaurant's HTML page and extracts structured information such as name, address, cuisine type, price range, description, and services.\n",
    "- **Input**:\n",
    "  - `html`: The raw HTML content of a restaurant's page.\n",
    "- **Output**:\n",
    "  - A dictionary containing extracted fields.\n",
    "- **Key Features**:\n",
    "  - Handles missing data gracefully.\n",
    "  - Handles addresses separated by commas.\n",
    "\n",
    "\n",
    "#### **Function**: `html_to_tsv`\n",
    "- **Description**:  \n",
    "  Scans the `HTMLs` folder inside the `data_folder` for all the html files, then processes every file with `extract_info_from_html`.\n",
    "- **Input (optional)**:\n",
    "  - `data_folder`: The folder where data will be stored; by default it is `DATA`.\n",
    "  - `max_workers`: the max number of concurrent HTML parsing tasks. \n",
    "- **Output**:\n",
    "  - Saves the TSV files in the folder `DATA/TSVs`.\n",
    "- **Key Features**:\n",
    "     - Uses `ThreadPoolExecutor` to speed up the process. \n",
    "- **Advice**:\n",
    "     - Fine-tune the `max_workers` parameter according to your CPU performance. As a rule of thumb, set `max_workers` to the number of CPU cores available. An estimated processing time of around 5 minutes is typical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing HTMLs: 100%|██████████| 1982/1982 [00:00<00:00, 24962.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been processed and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "html_to_tsv(data_folder=data_folder, max_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
